# Artillery Performance Test Configuration
# Video Processing Pipeline Load Testing

config:
  target: 'http://localhost:3000'
  phases:
    # Warm-up phase: 10 users for 2 minutes
    - duration: 120
      arrivalRate: 0.5
      name: "Warm-up Phase"
    # Main load phase: 100 users over 10 minutes
    - duration: 600
      arrivalRate: 10
      name: "Main Load Phase"
    # Cool-down phase: 20 users for 2 minutes
    - duration: 120
      arrivalRate: 1
      name: "Cool-down Phase"
  
  # Global configuration
  http:
    timeout: 300  # 5 minutes timeout for large file uploads
    pool: 20      # Connection pool size
  
  # Plugin configuration for metrics collection
  plugins:
    metrics-by-endpoint:
      useOnlyRequestNames: true
    publish-metrics:
      # Optional: Send metrics to external monitoring system
      # influxdb:
      #   host: 'localhost'
      #   port: 8086
      #   database: 'artillery_metrics'
  
  # Environment variables
  variables:
    # Test file configurations
    smallFileSize: 10485760    # 10MB
    mediumFileSize: 52428800   # 50MB
    largeFileSize: 104857600   # 100MB (max allowed)
    
    # File types distribution (weighted)
    fileTypes:
      - { type: "video/mp4", weight: 60 }
      - { type: "video/avi", weight: 15 }
      - { type: "video/mov", weight: 10 }
      - { type: "audio/mp3", weight: 10 }
      - { type: "audio/wav", weight: 5 }
    
    # Language codes
    languages:
      - { code: "en", weight: 70 }
      - { code: "es", weight: 15 }
      - { code: "fr", weight: 10 }
      - { code: "de", weight: 5 }
    
    # Video types for analysis configuration
    videoTypes:
      - { type: "educational", weight: 40 }
      - { type: "tutorial", weight: 30 }
      - { type: "presentation", weight: 20 }
      - { type: "demo", weight: 10 }

scenarios:
  # Scenario 1: Small file uploads (10MB) - 40% of traffic
  - name: "Small File Upload"
    weight: 40
    flow:
      - function: "generateSmallFile"
      - post:
          url: "/files"
          beforeRequest: "setUploadHeaders"
          form:
            file: "{{ smallFile }}"
            uploadData: "{{ smallFileConfig }}"
          capture:
            - json: "$.file._id"
              as: "fileId"
            - json: "$.processingHistory._id"
              as: "processingId"
          expect:
            - statusCode: 201
            - hasProperty: "file._id"
          afterResponse: "logUploadMetrics"
      
      # Optional: Check file status after upload
      - get:
          url: "/files"
          expect:
            - statusCode: 200
          afterResponse: "logFileListMetrics"

  # Scenario 2: Medium file uploads (50MB) - 35% of traffic
  - name: "Medium File Upload"
    weight: 35
    flow:
      - function: "generateMediumFile"
      - post:
          url: "/files"
          beforeRequest: "setUploadHeaders"
          form:
            file: "{{ mediumFile }}"
            uploadData: "{{ mediumFileConfig }}"
          capture:
            - json: "$.file._id"
              as: "fileId"
            - json: "$.processingHistory._id"
              as: "processingId"
          expect:
            - statusCode: 201
            - hasProperty: "file._id"
          afterResponse: "logUploadMetrics"
      
      # Wait and check processing status
      - think: 30
      - get:
          url: "/transcription/{{ fileId }}"
          expect:
            - statusCode: [200, 404]  # May not be processed yet
          afterResponse: "logTranscriptionMetrics"

  # Scenario 3: Large file uploads (100MB) - 20% of traffic
  - name: "Large File Upload"
    weight: 20
    flow:
      - function: "generateLargeFile"
      - post:
          url: "/files"
          beforeRequest: "setUploadHeaders"
          form:
            file: "{{ largeFile }}"
            uploadData: "{{ largeFileConfig }}"
          capture:
            - json: "$.file._id"
              as: "fileId"
            - json: "$.processingHistory._id"
              as: "processingId"
          expect:
            - statusCode: 201
            - hasProperty: "file._id"
          afterResponse: "logUploadMetrics"
      
      # Extended wait for large file processing
      - think: 60
      - get:
          url: "/files"
          expect:
            - statusCode: 200
          afterResponse: "logFileListMetrics"

  # Scenario 4: Invalid file uploads - 5% of traffic (error testing)
  - name: "Invalid File Upload"
    weight: 5
    flow:
      - function: "generateInvalidFile"
      - post:
          url: "/files"
          beforeRequest: "setUploadHeaders"
          form:
            file: "{{ invalidFile }}"
            uploadData: "{{ invalidFileConfig }}"
          expect:
            - statusCode: 400
          afterResponse: "logErrorMetrics"

# Custom functions for test data generation
functions:
  # Generate small test file (10MB)
  generateSmallFile: |
    function generateSmallFile(context, events, done) {
      const fileSize = context.vars.smallFileSize;
      const fileType = context.vars.fileTypes[Math.floor(Math.random() * context.vars.fileTypes.length)];
      const language = context.vars.languages[Math.floor(Math.random() * context.vars.languages.length)];
      
      // Create a buffer of the specified size
      const buffer = Buffer.alloc(fileSize, 'A');
      
      context.vars.smallFile = {
        value: buffer,
        options: {
          filename: `test-small-${Date.now()}.${fileType.split('/')[1]}`,
          contentType: fileType
        }
      };
      
      context.vars.smallFileConfig = JSON.stringify({
        languageCode: language.code,
        processingConfiguration: {
          segmentDuration: 60,
          analysisConfig: {
            videoType: context.vars.videoTypes[Math.floor(Math.random() * context.vars.videoTypes.length)].type,
            focusAreas: ["technical", "educational"],
            targetAudience: "developers",
            analysisLanguage: language.code,
            minInformativenessScore: 0.6,
            maxCombinedDuration: 120
          },
          clippingConfig: {
            maxClips: 5,
            minScoreThreshold: 6
          }
        }
      });
      
      return done();
    }

  # Generate medium test file (50MB)
  generateMediumFile: |
    function generateMediumFile(context, events, done) {
      const fileSize = context.vars.mediumFileSize;
      const fileType = context.vars.fileTypes[Math.floor(Math.random() * context.vars.fileTypes.length)];
      const language = context.vars.languages[Math.floor(Math.random() * context.vars.languages.length)];
      
      const buffer = Buffer.alloc(fileSize, 'B');
      
      context.vars.mediumFile = {
        value: buffer,
        options: {
          filename: `test-medium-${Date.now()}.${fileType.split('/')[1]}`,
          contentType: fileType
        }
      };
      
      context.vars.mediumFileConfig = JSON.stringify({
        languageCode: language.code,
        processingConfiguration: {
          segmentDuration: 90,
          analysisConfig: {
            videoType: context.vars.videoTypes[Math.floor(Math.random() * context.vars.videoTypes.length)].type,
            focusAreas: ["technical", "tutorial"],
            targetAudience: "students",
            analysisLanguage: language.code,
            minInformativenessScore: 0.7,
            maxCombinedDuration: 180
          },
          clippingConfig: {
            maxClips: 8,
            minScoreThreshold: 7
          }
        }
      });
      
      return done();
    }

  # Generate large test file (100MB)
  generateLargeFile: |
    function generateLargeFile(context, events, done) {
      const fileSize = context.vars.largeFileSize;
      const fileType = context.vars.fileTypes[Math.floor(Math.random() * context.vars.fileTypes.length)];
      const language = context.vars.languages[Math.floor(Math.random() * context.vars.languages.length)];
      
      const buffer = Buffer.alloc(fileSize, 'C');
      
      context.vars.largeFile = {
        value: buffer,
        options: {
          filename: `test-large-${Date.now()}.${fileType.split('/')[1]}`,
          contentType: fileType
        }
      };
      
      context.vars.largeFileConfig = JSON.stringify({
        languageCode: language.code,
        processingConfiguration: {
          segmentDuration: 120,
          analysisConfig: {
            videoType: context.vars.videoTypes[Math.floor(Math.random() * context.vars.videoTypes.length)].type,
            focusAreas: ["technical", "presentation"],
            targetAudience: "professionals",
            analysisLanguage: language.code,
            minInformativenessScore: 0.8,
            maxCombinedDuration: 300
          },
          clippingConfig: {
            maxClips: 10,
            minScoreThreshold: 8
          }
        }
      });
      
      return done();
    }

  # Generate invalid test file
  generateInvalidFile: |
    function generateInvalidFile(context, events, done) {
      const buffer = Buffer.from("This is not a video file", 'utf8');
      
      context.vars.invalidFile = {
        value: buffer,
        options: {
          filename: `invalid-${Date.now()}.txt`,
          contentType: "text/plain"
        }
      };
      
      context.vars.invalidFileConfig = JSON.stringify({
        languageCode: "en"
      });
      
      return done();
    }

  # Set appropriate headers for file upload
  setUploadHeaders: |
    function setUploadHeaders(requestParams, context, events, done) {
      requestParams.headers = {
        'User-Agent': 'Artillery-LoadTest/1.0',
        'Accept': 'application/json',
        'X-Test-Session': context.vars.$uuid
      };
      return done();
    }

  # Log upload metrics
  logUploadMetrics: |
    function logUploadMetrics(requestParams, response, context, events, done) {
      const metrics = {
        timestamp: new Date().toISOString(),
        endpoint: '/files',
        method: 'POST',
        statusCode: response.statusCode,
        responseTime: response.timings.response,
        fileSize: requestParams.form?.file?.value?.length || 0,
        contentType: requestParams.form?.file?.options?.contentType || 'unknown',
        sessionId: context.vars.$uuid
      };
      
      console.log(`UPLOAD_METRICS: ${JSON.stringify(metrics)}`);
      return done();
    }

  # Log file list metrics
  logFileListMetrics: |
    function logFileListMetrics(requestParams, response, context, events, done) {
      const metrics = {
        timestamp: new Date().toISOString(),
        endpoint: '/files',
        method: 'GET',
        statusCode: response.statusCode,
        responseTime: response.timings.response,
        fileCount: response.body?.length || 0,
        sessionId: context.vars.$uuid
      };
      
      console.log(`FILE_LIST_METRICS: ${JSON.stringify(metrics)}`);
      return done();
    }

  # Log transcription metrics
  logTranscriptionMetrics: |
    function logTranscriptionMetrics(requestParams, response, context, events, done) {
      const metrics = {
        timestamp: new Date().toISOString(),
        endpoint: '/transcription',
        method: 'GET',
        statusCode: response.statusCode,
        responseTime: response.timings.response,
        fileId: context.vars.fileId,
        sessionId: context.vars.$uuid
      };
      
      console.log(`TRANSCRIPTION_METRICS: ${JSON.stringify(metrics)}`);
      return done();
    }

  # Log error metrics
  logErrorMetrics: |
    function logErrorMetrics(requestParams, response, context, events, done) {
      const metrics = {
        timestamp: new Date().toISOString(),
        endpoint: '/files',
        method: 'POST',
        statusCode: response.statusCode,
        responseTime: response.timings.response,
        errorType: 'invalid_file',
        sessionId: context.vars.$uuid
      };
      
      console.log(`ERROR_METRICS: ${JSON.stringify(metrics)}`);
      return done();
    }

# Performance thresholds based on requirements
thresholds:
  # Response time thresholds
  - http.response_time.p95: 30000  # 95% of requests under 30 seconds
  - http.response_time.p99: 60000  # 99% of requests under 60 seconds
  - http.response_time.median: 15000  # Median response time under 15 seconds
  
  # Throughput thresholds
  - http.request_rate: 8  # Minimum 8 requests per second sustained
  - http.request_rate.max: 15  # Peak request rate
  
  # Error rate thresholds
  - http.codes.400: 5  # Max 5% 400 errors (invalid files)
  - http.codes.500: 1  # Max 1% 500 errors (server errors)
  - http.codes.201: 90  # Min 90% successful uploads
  
  # Custom metrics thresholds
  - upload_success_rate: 90  # Min 90% successful uploads
  - average_file_processing_time: 300000  # Max 5 minutes average processing time

# Output configuration
output:
  # Console output with detailed metrics
  console:
    level: info
  
  # Optional: Save results to file
  # file: ./artillery-results.json
  
  # Optional: Generate HTML report
  # html: ./artillery-report.html

# Additional configuration for monitoring
monitoring:
  # System resource monitoring (if available)
  system:
    enabled: true
    metrics:
      - cpu
      - memory
      - disk
      - network
  
  # Custom metrics collection
  custom:
    - name: "file_upload_duration"
      type: "histogram"
      description: "Duration of file upload operations"
    
    - name: "processing_queue_length"
      type: "gauge"
      description: "Length of processing queue"
    
    - name: "active_connections"
      type: "gauge"
      description: "Number of active connections"

# Test execution configuration
execution:
  # Parallel execution settings
  parallel: 4  # Run 4 parallel Artillery instances
  
  # Resource limits
  limits:
    maxMemory: "2GB"
    maxCpu: 80  # Percentage
  
  # Retry configuration
  retries:
    maxRetries: 3
    retryDelay: 1000

# Environment-specific overrides
environments:
  development:
    target: 'http://localhost:3000'
    phases:
      - duration: 60
        arrivalRate: 2
        name: "Dev Load Test"
  
  staging:
    target: 'https://staging-api.example.com'
    phases:
      - duration: 300
        arrivalRate: 5
        name: "Staging Load Test"
  
  production:
    target: 'https://api.example.com'
    phases:
      - duration: 600
        arrivalRate: 10
        name: "Production Load Test"
